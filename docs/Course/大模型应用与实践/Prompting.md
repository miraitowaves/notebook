

### 1. 提示词工程（Prompt Engineering）

提示词工程是指通过定制输入内容，使得大型语言模型（LLM）输出更加符合预期。提示词可以是让模型扮演某种角色（如老师或海盗），或使用特定的推理方法（如“思维链”）来处理输出。

```mermaid
graph LR
    A[提示词] --> B[调整模型输出]
    A --> C[设定角色]
    A --> D[使用特定推理方式]
    B --> E[更符合预期的输出]
```

### 2. 零样本与少样本提示（Zero-shot and Few-shot Prompting）

- **零样本提示（Zero-shot Prompting）**：直接给出任务指令，不提供任何示例。
- **少样本提示（Few-shot Prompting）**：在提示中提供几个示例，以引导模型给出更好的答案。

```mermaid
graph TD
    A[零样本提示] -->|没有示例| B[直接执行任务]
    C[少样本提示] -->|提供示例| D[任务执行更准确]
```

### 3. 上下文学习（In-Context Learning, ICL）

- 上下文学习指的是在推理阶段不对模型参数进行训练或优化，只提供任务描述及一些示例（零样本、单样本或少样本）。
- 该方法无需梯度更新，直接根据提供的上下文进行学习。

```mermaid
graph TD
    A[上下文学习] --> B[任务描述]
    B --> C[示例输入]
    C --> D[模型推断]
    D --> E[输出结果]
```

### 4. Emergent Abilities in Large Language Models

随着模型规模的增大，某些能力会在小模型中不存在，但在大模型中出现，这被称为“涌现能力”。例如，在大模型中，使用少样本提示可以大大提高某些任务的准确率。


> 由人们在大模型的研究中发现的现象，并非先存在了能够使得大模型具备涌现能力的方法

```mermaid
graph TD
    A[小模型] -->|随机准确率| B[任务表现]
    A -->|增加模型大小| C[大模型]
    C -->|高于随机准确率| D[任务表现提升]
```

### 5. 自注意力机制（Self-Attention Mechanism）

Transformer模型的核心机制是自注意力（Self-Attention），它允许模型在对序列中的每个词进行计算时同时考虑序列中的所有其他词。这种机制使得模型能够捕捉到更复杂的依赖关系。

```mermaid
graph TD
    A[输入序列] --> B[查询Q]
    A --> C[键K]
    A --> D[值V]
    B --> E[注意力权重计算]
    C --> E
    E --> F[加权求和输出]
    D --> F
```

### 6. 多头自注意力机制（Multi-Head Self-Attention）

多头自注意力机制通过并行的多个自注意力层，帮助模型学习到不同的特征表示，进而增强模型的表达能力。

```mermaid
graph TD
    A[输入序列] --> B[多头自注意力层]
    B --> C[输出序列]
    subgraph 多头自注意力层
        D1[自注意力1]
        D2[自注意力2]
        D3[自注意力3]
        D1 --> E1[加权输出1]
        D2 --> E2[加权输出2]
        D3 --> E3[加权输出3]
        E1 --> C
        E2 --> C
        E3 --> C
    end

```

### 7. 梯度下降与模型优化

传统的模型优化方法是通过在大规模标记数据集上进行反复的梯度更新来微调模型参数。每个任务都需要一个新的大型数据集，并且可能导致泛化能力差的问题。

```mermaid
graph TD
    A[预训练模型] --> B[大规模标记数据集]
    B --> C[梯度更新]
    C --> D[模型优化]
    D --> E[任务表现提升]
```

